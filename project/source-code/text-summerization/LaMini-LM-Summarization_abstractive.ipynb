{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Summarization from PDF and norml text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install sentencepiece\n",
    "%pip install langchain\n",
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import base64\n",
    "\n",
    "# LLM is a custom model trained on the LaMini dataset. It is a T5 model trained on the summarization task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model and tokenizer loading\n",
    "checkpoint = \"MBZUAI/LaMini-Flan-T5-248M\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(checkpoint, device_map='auto', torch_dtype=torch.float32)\n",
    "\n",
    "# LaMini-Flan-T5-248M install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file loader and preprocessing\n",
    "def file_preprocessing(file):\n",
    "    loader =  PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "    # split_documents returns a list of Text objects\n",
    "    final_texts = \"\"\n",
    "    for text in texts:\n",
    "        print(text)\n",
    "        final_texts = final_texts + text.page_content\n",
    "    return final_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"100%\" height=\"600\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit code \n",
    "st.set_page_config(layout=\"wide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for pdf summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM pipeline\n",
    "def llm_pipeline(filepath):\n",
    "    pipe_sum = pipeline(\n",
    "        'summarization',\n",
    "        model = base_model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 500, \n",
    "        min_length = 50)\n",
    "    input_text = file_preprocessing(filepath)\n",
    "    result = pipe_sum(input_text)\n",
    "    result = result[0]['summary_text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for normal text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM pipeline\n",
    "def llm_pipeline(input_text):\n",
    "    pipe_sum = pipeline(\n",
    "        'summarization',\n",
    "        model = base_model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 500, \n",
    "        min_length = 50)\n",
    "    result = pipe_sum(input_text)\n",
    "    result = result[0]['summary_text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary using normal text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "With the national polls around six months away, the Awami League and the BNP are going to hold programmes and counter-programmes today and tomorrow to show off their strength on the streets.\n",
    "\n",
    "The BNP will today march from Gabtoli to Jatrabari from 10:00am to 4:00pm in the capital and bring out processions in other cities and districts to realise its one-point demand for polls under a non-party interim government.\n",
    "\n",
    "Sources in the BNP said instructions were given to all Dhaka north and South city units to ensure huge gatherings.\n",
    "\n",
    "To counter BNP's programme, ruling Awami league will bring out what it termed \"a march for peace and development\" in the capital.\n",
    "\n",
    "At 3:00pm today, Dhaka city (South) AL will bring out a procession from Institution of Engineers, Bangladesh, that will end at Dhanmondi 32. AL General Secretary Obaidul Quader will join the programme.\n",
    "\n",
    "The unit is planning to gather over a lakh people in the event.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = llm_pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary from PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"Document Summarization App using Langauge Model\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload your PDF file\", type=['pdf'])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    if st.button(\"Summarize\"):\n",
    "        col1, col2 = st.columns(2)\n",
    "        filepath = \"data/\"+uploaded_file.name\n",
    "        with open(filepath, \"wb\") as temp_file:\n",
    "            temp_file.write(uploaded_file.read())\n",
    "        with col1:\n",
    "            st.info(\"Uploaded File\")\n",
    "            pdf_view = displayPDF(filepath)\n",
    "\n",
    "        with col2:\n",
    "            summary = llm_pipeline(filepath)\n",
    "            st.info(\"Summarization Complete\")\n",
    "            st.success(summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
