{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here will be covered : \n",
    "- Sentence Embedding\n",
    "- Sentence Similarity\n",
    "- Semantic Search\n",
    "- Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U sentence-transformers\n",
    "\n",
    "# sentence-transformers (BERT) is a library for computing sentence embeddings (sentence vectors) in Python and PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Embeding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# all-MiniLM-L6-v2 is a transformer model trained on a large corpus of English sentences and their paraphrases. It is a smaller version of the MiniLM model (6 layers instead of 12 layers). It was trained on the AllNLI and STS benchmark datasets. And it is the best performing model on the STS benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence','Sentences are passed as a list of string.', 'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\"\"\"\n",
    "text2 = \"\"\"\"\"\"\n",
    "emd1 = model.encode(\"Artificial intelligence is the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing, speech recognition and machine vision.\")\n",
    "emd2 = model.encode(\"Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice.\")\n",
    "# emd2 = model.encode(\"Tom deserves unbiased judgement\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity = util.cos_sim(emd1, emd2)\n",
    "cos_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Cosine Similarity Between all pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'A man is eating food.',\n",
    "    'A man is eating a piece of bread.',\n",
    "    'A man is riding a horse.',\n",
    "    'The girl is carrying a baby.',\n",
    "    'A woman is playing violin.',\n",
    "    'two men pushed carts through the woods.',\n",
    "    'A man is riding a white horse on an enclosed ground.',\n",
    "    'A monkey is playing drums.',\n",
    "    'A cheetah is running behind its prey.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enode sentences to get their embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarity between all pairs\n",
    "cosine_scores = util.cos_sin(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        all_sentence_combinations.append([cosine_scores[i][j], i, j])\n",
    "\n",
    "# Sort in decreasing order of the cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# x[0] is the criteria for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the pairs according to their cosine similarity score\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t\\t {} \\t\\t {:.4f}\".format(sentences[i], sentences[j], cosine_scores[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('clips/mfaq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"<Q>How many models can I host on Hugging Face?</Q>\"\n",
    "answer_1 = \"<A>All plans come with unlimited private models and datasets.\"\n",
    "answer_2 = \"<A>AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem.\"\n",
    "answer_3 = \"<A>Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode(question)\n",
    "corpus_embeddings = model.encode([answer_1, answer_2, answer_3])\n",
    "\n",
    "results = util.semantic_search(query_embedding, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
