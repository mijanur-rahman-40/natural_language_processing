{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Sentence Transformers, a \"CrossEncoder\" is a type of model architecture that is designed to encode and compare pairs of sentences simultaneously. Unlike the \"Siamese\" architecture, where the two sentences are encoded separately and then their representations are compared, the CrossEncoder processes both sentences together in a single forward pass.\n",
    "\n",
    "The CrossEncoder architecture is commonly used for tasks that involve comparing pairs of sentences, such as sentence similarity, semantic textual similarity, paraphrase identification, and natural language inference. It's especially useful when you want to calculate a single similarity score or label for the entire sentence pair.\n",
    "\n",
    "Here's a high-level overview of how a CrossEncoder works:\n",
    "\n",
    "1. **Input Encoding:** The two sentences in the pair are tokenized and encoded together as a single input. They are processed through a pre-trained transformer-based model, such as BERT, RoBERTa, or other variants, which produces a fixed-length vector representation for the entire sentence pair.\n",
    "\n",
    "2. **Similarity Calculation:** The encoded sentence pair representation is then passed through one or more fully connected layers or other transformation functions to calculate a similarity score. This score indicates how similar the two sentences are in terms of their semantic meaning, with higher scores indicating higher similarity.\n",
    "\n",
    "3. **Training:** During training, CrossEncoder models are often fine-tuned using supervised learning on tasks that require sentence pair comparisons. The model is trained with labeled data, where each sentence pair is associated with a similarity score or a binary label (e.g., paraphrase/non-paraphrase).\n",
    "\n",
    "The CrossEncoder architecture is particularly useful when you need a single model that can handle multiple types of similarity-related tasks, as it can provide efficient and accurate sentence pair comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the NLI task in NLP?**\n",
    "\n",
    "Natural Language Inference (NLI) is the task of determining whether the given “hypothesis” logically follows from the “premise”. In layman's terms, you need to understand whether the hypothesis is true, while the premise is your only knowledge about the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiNLI\n",
    " The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. The corpus is modeled on the SNLI corpus, but differs in that covers a range of genres of spoken and written text, and supports a distinctive cross-genre generalization evaluation. The corpus served as the basis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen. \n",
    "\n",
    "**Examples**\n",
    "\n",
    "Premise \t                                            Label \t    Hypothesis\n",
    "\n",
    "The Old One always comforted Ca'daan, except today. \tneutral \tCa'daan knew the Old One very well.\n",
    "\n",
    "Your gift is appreciated by each and every student \n",
    "who will benefit from your generosity.                  neutral \tHundreds of students will benefit from your generosity.\n",
    "\n",
    "yes now you know if if everybody like in August when \n",
    "everybody's on vacation or something we can dress \n",
    "a little more casual or \t                            contradiction \tAugust is a black out month for vacations in the company.\n",
    "\n",
    "\n",
    "At the other end of Pennsylvania Avenue, people began \n",
    "to line up for a White House tour. \t                    entailment \tPeople formed a line at the end of Pennsylvania Avenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers   \n",
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goo Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My personal traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/my_new_ds_train_eval_test.zip /content/drive/My\\ Drive/Colab\\ Notebooks/ML\\ Project\\ 2/my_new_ds_train_eval_test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download NLI Traning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-ques.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is NLP?</td>\n",
       "      <td>Natural Language Processing (NLP) is a field o...</td>\n",
       "      <td>NLP is a subfield of AI that deals with the pr...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the common NLP tasks?</td>\n",
       "      <td>Common NLP tasks include part-of-speech taggin...</td>\n",
       "      <td>NLP tasks mainly focus on analyzing the syntax...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         question  \\\n",
       "0                    What is NLP?   \n",
       "1  What are the common NLP tasks?   \n",
       "\n",
       "                                                text  \\\n",
       "0  Natural Language Processing (NLP) is a field o...   \n",
       "1  Common NLP tasks include part-of-speech taggin...   \n",
       "\n",
       "                                          hypothesis       label  \n",
       "0  NLP is a subfield of AI that deals with the pr...  entailment  \n",
       "1  NLP tasks mainly focus on analyzing the syntax...  entailment  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#As dataset, we use SNLI + MultiNLI\n",
    "#Check if dataset exsist. If not, download and extract  it\n",
    "nli_dataset_path = 'datasets/AllNLI.tsv.gz'\n",
    "\n",
    "if not os.path.exists(nli_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/AllNLI.tsv.gz', nli_dataset_path)\n",
    "\n",
    "\n",
    "# Read the AllNLI.tsv.gz file and create the training dataset\n",
    "logger.info(\"Read AllNLI train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(nli_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        label_id = label2int[row['label']]\n",
    "        if row['split'] == 'train':\n",
    "            train_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))\n",
    "        else:\n",
    "            dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open(nli_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "#     df_x = pd.read_csv(fIn, sep='\\t', names=['sentence1', 'sentence2','label_id'], quoting=csv.QUOTE_NONE)\n",
    "\n",
    "with gzip.open(nli_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    df_x = pd.read_csv(fIn, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head(1)['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head(1)['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/training_allnli-' + \\\n",
    "    datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CrossEncoder model. We use distilroberta-base as basis and setup it up to predict 3 labels\n",
    "model = CrossEncoder('distilroberta-base', num_labels=len(label2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap train_samples, which is a list ot InputExample, in a pytorch DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(\n",
    "    dev_samples, name='AllNLI-dev')\n",
    "\n",
    "\n",
    "# 10% of train data for warm-up\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But it takes too time like 20 hours for traning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=10000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity Between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# this is the best model for STSb dataset\n",
    "model = CrossEncoder('cross-encoder/stsb-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates.\n",
    "\"\"\"\n",
    "text2 = \"\"\"\n",
    "Gradient descent (GD) is not an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression). Due to its importance and ease of implementation, this algorithm is usually taught at the beginning of almost all machine learning courses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict([(text1,text2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use already fine-tuned Cross-Encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. NLI trained Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "model = CrossEncoder('cross-encoder/nli-distilroberta-base', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    (\"good public policy should make society healthier happier  safer and more productive\", \"scoial sciencists should be able to help us understand the world better\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_n = model.predict(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. STSb trained Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "model = CrossEncoder('cross-encoder/stsb-distilroberta-base',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_n = model.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert computed liast of list equal scores_hugg to simple labels\n",
    "label_mapping = [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "\n",
    "# original scores\n",
    "print(scores_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easy reading: convert list to singular label\n",
    "labels = [label_mapping[score_max] for score_max in scores_n.argmax(axis=1)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_btach_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/training_stsbenchmark_continue_training-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Cross Encoder Model on Custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 3\n",
    "model_save_path = 'output/my_training_ds-' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross encoder model\n",
    "my_model = CrossEncoder(\"distilroberta-base\", num_labels=len(label2int), max_length=512)\n",
    "\n",
    "# distilroberta-base is a smaller version of RoBERTa-base. It has 6 layers, 768 hidden size, 12 attention heads and about 82M parameters.\n",
    "\n",
    "# distilroberta-base is a smaller version of RoBERTa-base. It has 6 layers, 768 hidden size, 12 attention heads and about 82M parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace = True means we are modifying the original dataframe, not creating a new one and assigning it to df again \n",
    "df.drop('question', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String to Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting label to numeric\n",
    "df['label'].replace(label2int, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split into train_df, val_df, test_df\n",
    "train_df, val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding data as input example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_my = []\n",
    "test_samples = []\n",
    "\n",
    "# for i in range(len(train_df)):\n",
    "#     train_samples_my.append(InputExample(texts=[train_df.iloc[i]['question'], train_df.iloc[i]['answer']], label=train_df.iloc[i]['label']))\n",
    "\n",
    "# use anither way without for loop\n",
    "train_samples_my = [InputExample(texts=[train_df.iloc[i]['text'], train_df.iloc[i]['hypothesis']], label=train_df.iloc[i]['label']) for i in range(len(train_df))]\n",
    "\n",
    "test_samples = [InputExample(texts=[test_df.iloc[i]['text'], test_df.iloc[i]['hypothesis']], label=test_df.iloc[i]['label']) for i in range(len(test_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_my = DataLoader(train_samples_my, shuffle=True,batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_my = CESoftmaxAccuracyEvaluator.from_input_examples(test_samples, name='my_training_ds_evaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader_my) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "\n",
    "# warmup steps is a parameter that controls the learning rate during the first few epochs of training.\n",
    "# During the warm-up steps, the learning rate is linearly increased from 0 to the specified learning rate.\n",
    "# After the warm-up phase, the learning rate is decreasing again during training.\n",
    "# This is a common technique in transfer learning, especially for fine-tuning BERT models.\n",
    "\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "my_model.fit(train_dataloader=train_dataloader_my,\n",
    "             evaluator=evaluator_my,\n",
    "             epochs=1,\n",
    "             evaluation_steps=2000,\n",
    "             warmup_steps=warmup_steps,\n",
    "             save_best_model=True,\n",
    "             output_path=model_save_path)\n",
    "\n",
    "# evaluation_steps means how often the model should be evaluated on the dev set.\n",
    "# save_best_model=True means that only the best model is saved on disk (correctly classified most dev samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load my pre-trained cross-encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reloaded = CrossEncoder(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### eval on test set for single value outcome\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(test_samples, name='eval_test')\n",
    "evaluator(my_model, output_path=model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
