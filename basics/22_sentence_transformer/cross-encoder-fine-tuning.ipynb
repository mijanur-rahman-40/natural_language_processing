{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Sentence Transformers, a \"CrossEncoder\" is a type of model architecture that is designed to encode and compare pairs of sentences simultaneously. Unlike the \"Siamese\" architecture, where the two sentences are encoded separately and then their representations are compared, the CrossEncoder processes both sentences together in a single forward pass.\n",
    "\n",
    "The CrossEncoder architecture is commonly used for tasks that involve comparing pairs of sentences, such as sentence similarity, semantic textual similarity, paraphrase identification, and natural language inference. It's especially useful when you want to calculate a single similarity score or label for the entire sentence pair.\n",
    "\n",
    "Here's a high-level overview of how a CrossEncoder works:\n",
    "\n",
    "1. **Input Encoding:** The two sentences in the pair are tokenized and encoded together as a single input. They are processed through a pre-trained transformer-based model, such as BERT, RoBERTa, or other variants, which produces a fixed-length vector representation for the entire sentence pair.\n",
    "\n",
    "2. **Similarity Calculation:** The encoded sentence pair representation is then passed through one or more fully connected layers or other transformation functions to calculate a similarity score. This score indicates how similar the two sentences are in terms of their semantic meaning, with higher scores indicating higher similarity.\n",
    "\n",
    "3. **Training:** During training, CrossEncoder models are often fine-tuned using supervised learning on tasks that require sentence pair comparisons. The model is trained with labeled data, where each sentence pair is associated with a similarity score or a binary label (e.g., paraphrase/non-paraphrase).\n",
    "\n",
    "The CrossEncoder architecture is particularly useful when you need a single model that can handle multiple types of similarity-related tasks, as it can provide efficient and accurate sentence pair comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the NLI task in NLP?**\n",
    "\n",
    "Natural Language Inference (NLI) is the task of determining whether the given “hypothesis” logically follows from the “premise”. In layman's terms, you need to understand whether the hypothesis is true, while the premise is your only knowledge about the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiNLI\n",
    " The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. The corpus is modeled on the SNLI corpus, but differs in that covers a range of genres of spoken and written text, and supports a distinctive cross-genre generalization evaluation. The corpus served as the basis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen. \n",
    "\n",
    "**Examples**\n",
    "\n",
    "Premise \t                                            Label \t    Hypothesis\n",
    "\n",
    "The Old One always comforted Ca'daan, except today. \tneutral \tCa'daan knew the Old One very well.\n",
    "\n",
    "Your gift is appreciated by each and every student \n",
    "who will benefit from your generosity.                  neutral \tHundreds of students will benefit from your generosity.\n",
    "\n",
    "yes now you know if if everybody like in August when \n",
    "everybody's on vacation or something we can dress \n",
    "a little more casual or \t                            contradiction \tAugust is a black out month for vacations in the company.\n",
    "\n",
    "\n",
    "At the other end of Pennsylvania Avenue, people began \n",
    "to line up for a White House tour. \t                    entailment \tPeople formed a line at the end of Pennsylvania Avenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers   \n",
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goo Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My personal traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/my_new_ds_train_eval_test.zip /content/drive/My\\ Drive/Colab\\ Notebooks/ML\\ Project\\ 2/my_new_ds_train_eval_test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download NLI Traning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-ques.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is NLP?</td>\n",
       "      <td>Natural Language Processing (NLP) is a field o...</td>\n",
       "      <td>NLP is a subfield of AI that deals with the pr...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the common NLP tasks?</td>\n",
       "      <td>Common NLP tasks include part-of-speech taggin...</td>\n",
       "      <td>NLP tasks mainly focus on analyzing the syntax...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain the term 'parsing' in NLP.</td>\n",
       "      <td>In NLP,parsing refers to the process of analyz...</td>\n",
       "      <td>Parsing is a technique used in NLP to translat...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does sentiment analysis work in NLP?</td>\n",
       "      <td>Sentiment analysis in NLP involves using machi...</td>\n",
       "      <td>Sentiment analysis is a simple rule-based proc...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the role of word embeddings in NLP?</td>\n",
       "      <td>Word embeddings in NLP are dense vector repres...</td>\n",
       "      <td>Word embeddings are used in NLP to store words...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>How does software quality assurance ensure com...</td>\n",
       "      <td>Software quality assurance ensures compliance ...</td>\n",
       "      <td>Software quality assurance has no role in ensu...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>What are the advantages of conducting explorat...</td>\n",
       "      <td>Exploratory testing is a valuable approach in ...</td>\n",
       "      <td>Exploratory testing has no advantages in softw...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>How does software quality assurance ensure the...</td>\n",
       "      <td>Software quality assurance ensures the correct...</td>\n",
       "      <td>Software quality assurance has no role in ensu...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>What are the best practices for implementing s...</td>\n",
       "      <td>Implementing software quality assurance in saf...</td>\n",
       "      <td>There are no best practices for implementing s...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>How does software quality assurance contribute...</td>\n",
       "      <td>Software quality assurance contributes to redu...</td>\n",
       "      <td>Software quality assurance has no impact on re...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                                         What is NLP?   \n",
       "1                       What are the common NLP tasks?   \n",
       "2                   Explain the term 'parsing' in NLP.   \n",
       "3             How does sentiment analysis work in NLP?   \n",
       "4          What is the role of word embeddings in NLP?   \n",
       "..                                                 ...   \n",
       "477  How does software quality assurance ensure com...   \n",
       "478  What are the advantages of conducting explorat...   \n",
       "479  How does software quality assurance ensure the...   \n",
       "480  What are the best practices for implementing s...   \n",
       "481  How does software quality assurance contribute...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Natural Language Processing (NLP) is a field o...   \n",
       "1    Common NLP tasks include part-of-speech taggin...   \n",
       "2    In NLP,parsing refers to the process of analyz...   \n",
       "3    Sentiment analysis in NLP involves using machi...   \n",
       "4    Word embeddings in NLP are dense vector repres...   \n",
       "..                                                 ...   \n",
       "477  Software quality assurance ensures compliance ...   \n",
       "478  Exploratory testing is a valuable approach in ...   \n",
       "479  Software quality assurance ensures the correct...   \n",
       "480  Implementing software quality assurance in saf...   \n",
       "481  Software quality assurance contributes to redu...   \n",
       "\n",
       "                                            hypothesis          label  \n",
       "0    NLP is a subfield of AI that deals with the pr...     entailment  \n",
       "1    NLP tasks mainly focus on analyzing the syntax...     entailment  \n",
       "2    Parsing is a technique used in NLP to translat...     entailment  \n",
       "3    Sentiment analysis is a simple rule-based proc...     entailment  \n",
       "4    Word embeddings are used in NLP to store words...     entailment  \n",
       "..                                                 ...            ...  \n",
       "477  Software quality assurance has no role in ensu...  contradiction  \n",
       "478  Exploratory testing has no advantages in softw...  contradiction  \n",
       "479  Software quality assurance has no role in ensu...  contradiction  \n",
       "480  There are no best practices for implementing s...  contradiction  \n",
       "481  Software quality assurance has no impact on re...  contradiction  \n",
       "\n",
       "[482 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#As dataset, we use SNLI + MultiNLI\n",
    "#Check if dataset exsist. If not, download and extract  it\n",
    "nli_dataset_path = 'datasets/AllNLI.tsv.gz'\n",
    "\n",
    "if not os.path.exists(nli_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/AllNLI.tsv.gz', nli_dataset_path)\n",
    "\n",
    "\n",
    "# Read the AllNLI.tsv.gz file and create the training dataset\n",
    "logger.info(\"Read AllNLI train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(nli_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        label_id = label2int[row['label']]\n",
    "        if row['split'] == 'train':\n",
    "            train_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))\n",
    "        else:\n",
    "            dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(nli_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    df_x = pd.read_csv(fIn, sep='\\t', names=['sentence1', 'sentence2','label_id'], quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head(1)['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head(1)['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/training_allnli-' + \\\n",
    "    datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CrossEncoder model. We use distilroberta-base as basis and setup it up to predict 3 labels\n",
    "model = CrossEncoder('distilroberta-base', num_labels=len(label2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap train_samples, which is a list ot InputExample, in a pytorch DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(\n",
    "    dev_samples, name='AllNLI-dev')\n",
    "\n",
    "\n",
    "# 10% of train data for warm-up\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But it takes too time like 20 hours for traning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=10000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use already fine-tuned Cross-Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "model_hugg = CrossEncoder('cross-encoder/nli-distilroberta-base', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    (\"good public policy should make society healthier happier  safer and more productive\", \"scoial sciencists should be able to help us understand the world better\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_hugg = model_hugg.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert computed liast of list equal scores_hugg to simple labels\n",
    "label_mapping = [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "\n",
    "# original scores\n",
    "print(scores_hugg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easy reading: convert list to singular label\n",
    "labels = [label_mapping[score_max] for score_max in scores_hugg.argmax(axis=1)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_btach_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/training_stsbenchmark_continue_training-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Cross Encoder Model on Custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 3\n",
    "model_save_path = 'output/my_training_ds-' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross encoder model\n",
    "my_model = CrossEncoder(\"distilroberta-base\", num_labels=len(label2int), max_length=512)\n",
    "\n",
    "# distilroberta-base is a smaller version of RoBERTa-base. It has 6 layers, 768 hidden size, 12 attention heads and about 82M parameters.\n",
    "\n",
    "# distilroberta-base is a smaller version of RoBERTa-base. It has 6 layers, 768 hidden size, 12 attention heads and about 82M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\n",
    "    'contradiction': 0,\n",
    "    'entailment': 1,\n",
    "    'neutral': 2\n",
    "}\n",
    "\n",
    "rows = [\n",
    "    {\n",
    "        'sentence1': 'I like to eat apples.',\n",
    "        'sentence2': 'Apples are my favorite fruit.',\n",
    "        'label': 1\n",
    "    },\n",
    "    {\n",
    "        'sentence1': 'I like to eat apples.',\n",
    "        'sentence2': 'Apples are my favorite fruit.',\n",
    "        'label': 1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_my = []\n",
    "for i in range(len(rows)):\n",
    "    train_samples_my.append(InputExample(texts=[train_samples[i]['sentence1'], train_samples[i]['sentence2']], label=train_samples[i]['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_my = DataLoader(train_samples_my, shuffle=True,batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_my = CESoftmaxAccuracyEvaluator.from_input_examples(test_samples, name='my-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "\n",
    "# warmup steps is a parameter that controls the learning rate during the first few epochs of training.\n",
    "# During the warm-up steps, the learning rate is linearly increased from 0 to the specified learning rate.\n",
    "# After the warm-up phase, the learning rate is decreasing again during training.\n",
    "# This is a common technique in transfer learning, especially for fine-tuning BERT models.\n",
    "\n",
    "\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "my_model.fit(train_dataloader=train_dataloader,\n",
    "             evaluator=evaluator,\n",
    "             epochs=1,\n",
    "             evaluation_steps=2000,\n",
    "             warmup_steps=warmup_steps,\n",
    "             save_best_model=True,\n",
    "             output_path=model_save_path)\n",
    "# evaluation_steps means how often the model should be evaluated on the dev set.\n",
    "# save_best_model=True means that only the best model is saved on disk (correctly classified most dev samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
