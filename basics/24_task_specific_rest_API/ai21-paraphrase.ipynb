{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY  = \"Bearer MCdEeTWTwKAq05WET22JdgBFAFdM4KHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://api.ai21.com/studio/v1/paraphrase\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"Authorization\": API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Gradient Descent is known as one of the most commonly used optimization algorithms to train machine learning models by means of minimizing errors between actual and expected results. Further, gradient descent is also used to train Neural Networks.In mathematical terminology, Optimization algorithm refers to the task of minimizing/maximizing an objective function f(x) parameterized by x. Similarly, in machine learning, optimization is the task of minimizing the cost.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"text\": text,\n",
    "    \"style\": \"general\"\n",
    "}\n",
    "\n",
    "response = requests.post(url,json=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'style'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detail\":\"'text' length exceeds max character limit: 500.\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = response.json()\n",
    "suggestions = response_json['suggestions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the most commonly used optimization algorithms to train machine learning models is gradient descent, which minimizes errors between actual and expected results by using gradient descent. In addition, gradient descent is also used to train neural networks. An optimization algorithm, in mathematics, minimizes or maximizes a function parameterized by x. In machine learning\n",
      "In machine learning, gradient descent is used to reduce errors between actual and expected results, making it one of the most commonly used optimization algorithms. Similarly, gradient descent is also used to train neural networks. An optimization algorithm in mathematics refers to the task of minimizing or maximizing an objective function f(x) parameterized by x. In machine learning, it refers to the task of minimising/maximizing an objective function f(x) parameterized by x.\n",
      "As one of the most common optimization algorithms for training machine learning models, gradient descent minimizes errors between actual and expected results by minimizing errors between actual and expected results. Furthermore, gradient descent is also used to train neural networks. As in mathematics, an optimization algorithm minimizes/maximizes an objective function f(x) with parameters x.\n",
      "Machine learning models are commonly trained using Gradient Descent because it minimizes errors between actual results and expected results, one of the most commonly used optimization algorithms. A gradient descent algorithm can also be used in machine learning to train neural networks. According to mathematical terminology, optimization algorithms minimize/maximize objective functions f(x) parameterized by x. Machine learning uses a similar approach.\n",
      "In order to minimize errors between actual and expected results, gradient descent is one of the most widely used optimization algorithms used in machine learning models. The Gradient Descent algorithm is also used in neural network training. The optimization algorithm in mathematics is used to minimize/maximize an objective function f(x) parameterized by x.\n",
      "A machine learning model can be trained by gradient descent by minimizing errors between the actual and expected results. Gradient descent is also used to train Neural Networks. A mathematical optimization algorithm minimizes or maximizes a function f(x) parameterized by x. Machine learning uses gradient descent to train neural networks.\n",
      "Machine learning models are often trained using Gradient Descent as a way to minimize errors between actual and expected results, making it one of the most commonly used optimization algorithms. Furthermore, gradient descent is also applied to neural networks. An optimization algorithm is a method for minimizing/maximizing an objective function f(x) parameterized by x, as defined in mathematical terms.\n",
      "It is one of the most commonly used optimization algorithms for training machine learning models, as it minimizes the error between expected and actual results. Similarly, gradient descent is also used to train neural networks. A machine learning optimization algorithm aims to minimize/maximize the objective function f(x) parameterized by x.\n",
      "By minimizing errors between actual and expected results, gradient descent is one of the most popular optimization algorithms for machine learning models. Additionally, gradient descent is used to train neural networks. An optimization algorithm, in mathematics, is a method of minimizing or maximizing a function that is parameterized by x. In machine learning, it is similar.\n",
      "Using gradient descent to minimize differences between actual and expected results, one of the most commonly used optimization algorithms for machine learning is gradient descent. Neural networks can also be trained with gradient descent. In mathematical terminology, Optimization algorithms are used to minimize/maximize objective functions parameterized by x. In machine learning, however,\n"
     ]
    }
   ],
   "source": [
    "# print all suggestions\n",
    "for i in range(len(suggestions)):\n",
    "    print(suggestions[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records([1,3], index = [1,2] )\n",
    "\n",
    "# Cell\n",
    "# Path: basics/24_task_specific_rest_API/ai21-paraphrase.ipynb\n",
    "pd.DataFrame.from_records([1,3], index = [1,2] )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
