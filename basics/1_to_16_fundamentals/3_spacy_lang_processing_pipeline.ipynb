{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain\n",
      "america\n",
      "ate\n",
      "100\n",
      "$\n",
      "of\n",
      "samosa\n",
      ".\n",
      "Then\n",
      "he\n",
      "said\n",
      "I\n",
      "can\n",
      "do\n",
      "this\n",
      "all\n",
      "day\n",
      ".\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "data = 'Captain america ate 100$ of samosa. Then he said I can do this all day.'\n",
    "doc = nlp(data)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "nlp.pipe_names\n",
    "\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f0607acf100>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f0607acf700>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f0607bdbdf0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f060787b100>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f060774fc40>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f0607bdbe60>)]\n",
      "Captain  |  PROPN  |  Captain\n",
      "america  |  PROPN  |  america\n",
      "ate  |  VERB  |  eat\n",
      "100  |  NUM  |  100\n",
      "$  |  NUM  |  $\n",
      "of  |  ADP  |  of\n",
      "samosa  |  PROPN  |  samosa\n",
      ".  |  PUNCT  |  .\n",
      "Then  |  ADV  |  then\n",
      "he  |  PRON  |  he\n",
      "said  |  VERB  |  say\n",
      "I  |  PRON  |  I\n",
      "can  |  AUX  |  can\n",
      "do  |  VERB  |  do\n",
      "this  |  PRON  |  this\n",
      "all  |  DET  |  all\n",
      "day  |  NOUN  |  day\n",
      ".  |  PUNCT  |  .\n"
     ]
    }
   ],
   "source": [
    "# For english pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(nlp.pipeline)\n",
    "\n",
    "\n",
    "doc = nlp(data)\n",
    "# dep \n",
    "for token in doc:\n",
    "    print(token.text , \" | \", token.pos_ , \" | \", token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$45 billion  |  MONEY  |  Monetary values, including unit\n",
      "Tesla Inc\n",
      "twitter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
    "\n",
    "# knowing labels \n",
    "for ent in doc.ents:\n",
    "    print(ent.text , \" | \", ent.label_, \" | \", str(spacy.explain(ent.label_))) # ent is entity, means a noun, a named entity recognition\n",
    "\n",
    "# noun chunks\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)\n",
    "\n",
    "# visualizing with label information\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Controlling Pipelines items over the existing__(Custom Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ner']\n",
      "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$45 billion  |  MONEY  |  Monetary values, including unit\n",
      "Tesla Inc\n",
      "twitter\n"
     ]
    }
   ],
   "source": [
    "source_nlp = spacy.load('en_core_web_sm')\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# nlp.add_pipe(source_nlp.create_pipe('sentencizer'))\n",
    "nlp.add_pipe('ner', source=source_nlp)\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text , \" | \", ent.label_, \" | \", str(spacy.explain(ent.label_)))\n",
    "\n",
    "# noun chunks\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Execises__\n",
    "\n",
    "##### 1.\n",
    "- Get all the proper nouns from a given text in a list and also count how many of them.\n",
    "- **Proper Noun** means a noun that names a particular person, place, or thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n",
    "\n",
    "# https://spacy.io/usage/linguistic-features\n",
    "\n",
    "#creating the nlp object\n",
    "doc = nlp(text)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. \n",
    "- Get all companies names from a given text and also the count of them.\n",
    "- **Hint**: Use the spacy **ner** functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in \n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
    "\n",
    "\n",
    "doc = nlp(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
