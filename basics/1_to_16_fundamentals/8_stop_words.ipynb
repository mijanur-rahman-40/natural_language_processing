{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop word means a word that is so commonly used, that it's considered noise.\n",
    "# Stop words are words like \"a\", \"the\", \"and\", \"but\", \"if\", \"or\" and so on.\n",
    "# Stop words are usually removed from the text before processing.\n",
    "# They are usually removed to prevent the model from getting confused.\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "for\n",
      "a\n",
      "over\n",
      "his\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = 'Musk wants time to prepare for a trial over his'\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "   if token.is_stop:\n",
    "      print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Musk wants time prepare trial'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard way to remove stop words in pre-processing\n",
    "\n",
    "def preprocessing(text):\n",
    "    doc= nlp(text)\n",
    "    # list comprehension, it means for each token in doc, if the token is not a stop word, then add it to the filtered_tokens list\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    # next preprocessing steps\n",
    "    # stemming\n",
    "    # lemmatization\n",
    "    # return no_stop_words\n",
    "\n",
    "    return \" \".join(no_stop_words)\n",
    "\n",
    "# custom stop words\n",
    "preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13087, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/doj_press.json', lines=True)\n",
    "# df.head(5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12810</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12672</td>\n",
       "      <td>12887</td>\n",
       "      <td>13080</td>\n",
       "      <td>2400</td>\n",
       "      <td>253</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>13-526</td>\n",
       "      <td>Northern California Real Estate Investor Agree...</td>\n",
       "      <td>WASHINGTON – ING Bank N.V., a financial inst...</td>\n",
       "      <td>2018-04-13T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Criminal Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>8399</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "count    12810                                              13087   \n",
       "unique   12672                                              12887   \n",
       "top     13-526  Northern California Real Estate Investor Agree...   \n",
       "freq         3                                                  8   \n",
       "\n",
       "                                                 contents  \\\n",
       "count                                               13087   \n",
       "unique                                              13080   \n",
       "top       WASHINGTON – ING Bank N.V., a financial inst...   \n",
       "freq                                                    2   \n",
       "\n",
       "                             date topics           components  \n",
       "count                       13087  13087                13087  \n",
       "unique                       2400    253                  810  \n",
       "top     2018-04-13T00:00:00-04:00     []  [Criminal Division]  \n",
       "freq                           20   8399                 2680  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topics[0]\n",
    "type(df.topics[0])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4688, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding non empty topics\n",
    "# df[df.topics.apply(lambda x: len(x) > 0)].head(5)\n",
    "# or\n",
    "# df = df[df['topics'].map(lambda d: len(d)) > 0]\n",
    "df = df[df['topics'].str.len() != 0]\n",
    "df.head(5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6286"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking first 100 data\n",
    "df = df.head(100)\n",
    "df.shape\n",
    "# iloc is used to access a group of rows and columns by label(s) or a boolean array in the given dataframe.\n",
    "# df.iloc[0]\n",
    "# df.iloc[0]['contents']\n",
    "df['contents']\n",
    "# print the second content\n",
    "# df.iloc[1]['contents']\n",
    "len(df.iloc[0]['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.iloc[0]['contents'][:1000])\n",
    "type(df['contents'])\n",
    "# creating a new column in the dataframe and applying preprocessing function to it\n",
    "df['contents_new'] = df['contents'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The U.S. Department of Justice, the U.S. Environmental Protection Agency (EPA), and the Rhode Island\n"
     ]
    }
   ],
   "source": [
    "df.head(1)\n",
    "# len(df.iloc[0]['contents'])\n",
    "# # printing fisrt 200 characters of the first content\n",
    "print(df['contents'].iloc[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Department Justice U.S. Environmental Protection Agency EPA Rhode Island Department Environment'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[0]['contents_new'])\n",
    "df['contents_new'].iloc[0][:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
